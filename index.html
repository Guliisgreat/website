<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Li Gu</title>

  <meta name="author" content="Li Gu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Li Gu</name>
                  </p>
                  <p>Hi! I am a research engineer at Noah‚Äôs Ark Lab, Huawei Canada in Toronto</a>, where I work on
                    computer vision and machine learning. I am currently working on xxx, supervised by <a
                      href="https://users.encs.concordia.ca/~wayang/">Prof. Wang Yang</a>.
                  </p>
                  <p>
                    I obtained my Master's degree in Computer Engineering at University of Toronto in 2018.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:guliisworking@hotmail.com">Email</a> &nbsp/&nbsp
                    <!--                 <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                    <!--                 <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.ca/citations?user=crdHC0sAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                    <!--                 <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                    <a href="https://github.com/Guliisgreat">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/li-gu/">Linkedin</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publication</heading>
                  <p>
                    My primary research interests lie at the intersection of machine learning and computer vision.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>



              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/meta_dmoe.png" alt="meta_dmoe" width="300" height="150" style="border-style: none">
                </td>
                <td width="75%" valign="middle">

                  <papertitle>Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from Mixture-of-Experts
                  </papertitle>

                  <br>
                  Tao Zhong*, Zhixiang Chi*, <strong>Li Gu*</strong>, Yang Wang, Yuanhao Yu, Jin Tang
                  <br>
                  <em>NeurIPS</em>, 2022.
                  <br>

                  <a href="https://arxiv.org/abs/2210.03885">Paper</a> /
                  <a href="data/Meta-DMoE_NeurIPS2022.pptx">Slides</a> /
                  <a href="https://github.com/n3il666/Meta-DMoE">Code</a>
                  <p></p>

                  <p>
                    Propose a new framework for unsupervised test-time adaption towards domain shift; Formulate the
                    adaptation process as knowledge distillation and meta-learn the scheme of knowledge aggregation from
                    multiple source domains.
                  </p>

                </td>
              </tr>


              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/orbit_2022.png" alt="orbit_2022" width="300" height="150" style="border-style: none">
                </td>
                <td width="75%" valign="middle">

                  <papertitle>Improving ProtoNet for Few-Shot Video Object Recognition: Winner of ORBIT Challenge 2022
                  </papertitle>

                  <br>
                  <strong>Li Gu</strong>, Zhixiang Chi*, Huan Liu*, Yuanhao Yu, Yang Wang
                  <br>
                  <em>CVPR</em> 2022 VisWiz workshop.
                  <br>
                  Winning team at <a href="https://eval.ai/web/challenges/challenge-page/1438/overview">ORBIT few-shot object recognition challenge</a><h1 style="color:Tomato;">Award cash prizes of 2,500 USD</h1>
                  <br>
                  

                  <a href="https://arxiv.org/abs/2210.00174">Paper</a> /
                  <a href="/data/orbit_2022.pdf">Slides</a> /
                  <a href="https://github.com/Guliisgreat/ORBIT-2022-winner-method">Code</a>
                  <p></p>

                  <p>
                    Propose a new framework for unsupervised test-time adaption towards domain shift; Formulate the
                    adaptation process as knowledge distillation and meta-learn the scheme of knowledge aggregation from
                    multiple source domains.
                  </p>

                </td>
              </tr>





</body>

</html>